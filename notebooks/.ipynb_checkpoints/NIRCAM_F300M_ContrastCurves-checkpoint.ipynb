{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import pyklip.klip\n",
    "import pyklip.instruments.Instrument as Instrument\n",
    "import pyklip.parallelized as parallelized\n",
    "import pyklip.rdi as rdi\n",
    "import pyklip.fakes as fakes\n",
    "import glob\n",
    "from astropy.table import Table\n",
    "from astropy.table import join\n",
    "from astropy.table import vstack\n",
    "import pandas as pd\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Contrast Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NIRCAM data simulated by the Space Telescope Science Institute, we'd like to estimate the contrast needed by a given planet at different separations from its host star in order for it to be detectable by the James Webb Space Telescope. This notebook performs an analysis of contrast in starlight-subtracted images in order to generate contrast curves for the visualization of this information.\n",
    "The first step in this process is thus utilzing the pyKLIP algorithm to remove starlight, then measuring the contrast in the image at varying distances. However, this PSF subtraction can result in the distortion of planet spectrum, and an oversubtraction of flux from the image as a whole. Thereofore, we also measure the algortithm throughput as a function of planet sepration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "This loads loads in our simulated JWST data, specifying the roll angle (10 arcseconds is the maximum roll angle) as well as the center as the image and the inner working angle. It combines images from both roll angles (0 and 10 arcseconds) to create a full sequence of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset to be used\n",
    "filtername = \"f300m\"\n",
    "\n",
    "# read in roll 1\n",
    "with fits.open(\"old_simulated_data/NIRCam_target_Roll1_{0}.fits\".format(filtername)) as hdulist:\n",
    "    roll1_cube = hdulist[0].data\n",
    "\n",
    "# read in roll 2\n",
    "with fits.open(\"old_simulated_data/NIRCam_target_Roll2_{0}.fits\".format(filtername)) as hdulist:\n",
    "    roll2_cube = hdulist[0].data  \n",
    "\n",
    "# combine the two rows\n",
    "full_seq = np.concatenate([roll1_cube, roll2_cube], axis=0)\n",
    "\n",
    "# two rolls are offset 10 degrees\n",
    "pas = np.append([0 for _ in range(roll1_cube.shape[0])], [10 for _ in range(roll2_cube.shape[0])])\n",
    "\n",
    "# for each image, the (x,y) center where the star is is just the center of the image\n",
    "centers = np.array([np.array(frame.shape)/2. for frame in full_seq])\n",
    "\n",
    "# give it some names, just in case we want to refer to them\n",
    "filenames = np.append([\"roll1_{0}\".format(i) for i in range(roll1_cube.shape[0])],\n",
    "                      [\"roll2_{0}\".format(i) for i in range(roll1_cube.shape[0])])\n",
    "\n",
    "#Define dataset\n",
    "dataset = Instrument.GenericData(full_seq, centers, IWA=4, parangs=pas, filenames=filenames)\n",
    "dataset.flipx = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Klip\n",
    "\n",
    "Use the pyklip algortihm on the dataset in order to remove starlight from the images. Using KLIP-ADI reductions, we will break the image into 9 concentric annuli, and each annuli into 4 azimuthal sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelized.klip_dataset(dataset, outputdir=\"./\", fileprefix=\"pyklip-f300m-ADI-k50a9s4m1\", annuli=9, \n",
    "                          subsections=4, numbasis=[1,5,10,20,50], mode=\"ADI\", movement=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Any Real Planets in Image\n",
    "\n",
    "There are two \"real\" planets already in this dataset, but we don't want to include them in our noise estimation. Their positions are at (41,54) and (43,70) respectively. We will therefore mask these this positions with nans before calculating the contrast in our images. We used 5 KL modes to KLIP our data, but to create the contrast curve we only need 1 frame. We'll arbitrarily chose the KL mode with an index of 2 to accomplish this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the KLIP-ed dataset\n",
    "with fits.open(\"pyklip-f300m-ADI-k50a9s4m1-KLmodes-all.fits\") as hdulist:\n",
    "    adi_cube = hdulist[0].data\n",
    "    adi_centers = [hdulist[0].header['PSFCENTX'], hdulist[0].header['PSFCENTY']]\n",
    "\n",
    "    \n",
    "#Plot the KL10 Cube (index of 2)\n",
    "plt.figure() \n",
    "plt.imshow(adi_cube[2], interpolation='nearest', cmap='inferno')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask the 1st planet\n",
    "planet1_peak_x = 41 \n",
    "planet1_peak_y = 54\n",
    "\n",
    "#Create an array with the indices are that of KL mode frame with index 2\n",
    "ydat, xdat = np.indices(adi_cube[2].shape)\n",
    "\n",
    "#Set the FWHM of the PSF\n",
    "psf_fwhm = 6\n",
    "\n",
    "#Calculate the distance around the planet to be masked\n",
    "distance_from_planet1 = np.sqrt((xdat - planet1_peak_x)**2 + (ydat - planet1_peak_y)**2)\n",
    "\n",
    "#Mask\n",
    "adi_cube[2][np.where(distance_from_planet1 <= 2*psf_fwhm)] = np.nan\n",
    "\n",
    "#fakes.gaussfit2d(psf_frame, 71, 30, searchrad=3, guessfwhm=2, guesspeak=1, refinefit=True)\n",
    "#Use pyklip.fakes to gaussfit2d and centroid on tiny planets\n",
    "#Mask the second planet\n",
    "planet2_peak_x = 43\n",
    "planet2_peak_y = 70\n",
    "distance_from_planet2 = np.sqrt((xdat - planet2_peak_x)**2 + (ydat - planet2_peak_y)**2)\n",
    "adi_cube[2][np.where(distance_from_planet2 <= 2*psf_fwhm)] = np.nan\n",
    "\n",
    "#plot the new masked data\n",
    "plt.figure()\n",
    "plt.imshow(adi_cube[2], interpolation='nearest', cmap='inferno')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the Contrast\n",
    "\n",
    "Using the pyKLIP function meas_contrast, we can compute the 5 $\\sigma$ noise at each separation in our image. For this function, we again need to specify our planet's FWHM as well as our outer working angle and the center of our input frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWA = 65 #Setting this to be distance between star and outer edge of image\n",
    "\n",
    "#Measuring the contrast in the image\n",
    "contrast_seps, contrast = pyklip.klip.meas_contrast(dat = adi_cube[2], \n",
    "                                                     iwa = dataset.IWA, \n",
    "                                                     owa = OWA, \n",
    "                                                     resolution = (psf_fwhm), \n",
    "                                                     center = adi_centers,\n",
    "                                                     low_pass_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot contrast curve!\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(contrast_seps, contrast, color = \"teal\")\n",
    "plt.xlabel(\"Separation (pixels)\")\n",
    "plt.ylabel(\"Contrast (5 $\\sigma$)\")\n",
    "plt.title(\"Non-Calibrated Contrast Curve\")\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.savefig(\"contrast_adi2.png\", dpic = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing throughput\n",
    "\n",
    "Now that we've created our contrast curve, we can calculate the throughput of our KLIP reduced images. In order to optimize this calculation, we need to inject multiple fake planets at varying separations and postion angles to get a feel for how throughput changes across the image.\n",
    "\n",
    "### The Fake Planets to be Injected:\n",
    "\n",
    "The injected fake planets will be scaled down versions of the unocculted PSF. The following code simply crops and centers this unocculted psf to prepare it for injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in unocculted PSF\n",
    "with fits.open(\"old_simulated_data/NIRCam_unocculted_{0}.fits\".format(filtername)) as hdulist:\n",
    "    psf_cube = hdulist[0].data \n",
    "    psf_head = hdulist[0].header\n",
    "    \n",
    "# collapse reference psf in time\n",
    "psf_frame = np.nanmean(psf_cube, axis=0)\n",
    "\n",
    "# find the centroid\n",
    "bestfit = fakes.gaussfit2d(psf_frame, 71, 30, searchrad=3, guessfwhm=2, guesspeak=1, refinefit=True)\n",
    "\n",
    "psf_xcen, psf_ycen = bestfit[2:4]\n",
    "\n",
    "# recenter PSF to that location\n",
    "x, y = np.meshgrid(np.arange(-20,20.1,1), np.arange(-20,20.1,1))\n",
    "x += psf_xcen\n",
    "y += psf_ycen\n",
    "\n",
    "psf_stamp = scipy.ndimage.map_coordinates(psf_frame, [y,x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a dataset\n",
    "First, we need to generate data of the science target taken at two telescope roll angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset to be used\n",
    "filtername = \"f300m\"\n",
    "\n",
    "# read in roll 1\n",
    "with fits.open(\"old_simulated_data/NIRCam_target_Roll1_{0}.fits\".format(filtername)) as hdulist:\n",
    "    roll1_cube = hdulist[0].data\n",
    "\n",
    "# read in roll 2\n",
    "with fits.open(\"old_simulated_data/NIRCam_target_Roll2_{0}.fits\".format(filtername)) as hdulist:\n",
    "    roll2_cube = hdulist[0].data  \n",
    "\n",
    "# combine the two rows\n",
    "full_seq = np.concatenate([roll1_cube, roll2_cube], axis=0)\n",
    "\n",
    "# two rolls are offset 10 degrees\n",
    "pas = np.append([0 for _ in range(roll1_cube.shape[0])], [10 for _ in range(roll2_cube.shape[0])])\n",
    "\n",
    "# for each image, the (x,y) center where the star is is just the center of the image\n",
    "centers = np.array([np.array(frame.shape)//2. for frame in full_seq])\n",
    "\n",
    "# give it some names, just in case we want to refer to them\n",
    "filenames = np.append([\"roll1_{0}\".format(i) for i in range(roll1_cube.shape[0])],\n",
    "                      [\"roll2_{0}\".format(i) for i in range(roll1_cube.shape[0])])\n",
    "\n",
    "#Define dataset\n",
    "dataset = Instrument.GenericData(full_seq, centers, IWA=4, parangs=pas, filenames=filenames)\n",
    "dataset.flipx = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting the fake planets\n",
    "\n",
    "Now that we have our data and have prepare our fake planet to be injected, we can choose how many we'd like to put into our dataset, what we want their relative fluxes to be, and their separations from the planet. For now, we'll inject three planets into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's choose our contrasts so that the planets get fainter as we go further from the star\n",
    "psf_stamp_input = np.array([psf_stamp for j in range(12)])\n",
    "input_contrasts = [1e-3, 7e-4, 3e-4]\n",
    "planet_seps = [15, 25, 35]\n",
    "pas = [0, 90, 180, 270]\n",
    "\n",
    "#Now injecting the fake planets in a spiral:\n",
    "for input_contrast, planet_sep in zip(input_contrasts, planet_seps):\n",
    "    planet_fluxes = psf_stamp_input*input_contrast\n",
    "    \n",
    "    for pa in pas:\n",
    "        fakes.inject_planet(frames = dataset.input, \n",
    "                            centers=dataset.centers, \n",
    "                            inputflux=planet_fluxes, \n",
    "                            astr_hdrs=dataset.wcs, \n",
    "                            radius=planet_sep,\n",
    "                            pa = pa)\n",
    "\n",
    "plt.imshow(dataset.input[0], interpolation=\"nearest\", cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KLIP - Recover Planets\n",
    "\n",
    "Now that we've injected our fake planets, we can check how well we were able to recover them by running KLIP. We'll only use 1 subsection and 1 annulus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set output directory\n",
    "outputdir = 'contrastcurves'\n",
    "fileprefix = 'FAKE_KLIP_ADI_A9K5S1M1'\n",
    "numbasis = [1,5,10,20,50]\n",
    "\n",
    "\n",
    "#Run KLIP on dataset with injected fakes\n",
    "parallelized.klip_dataset(dataset, \n",
    "                          outputdir=outputdir, \n",
    "                          fileprefix=fileprefix, \n",
    "                          algo = 'klip', \n",
    "                          annuli=1, \n",
    "                          subsections=1, \n",
    "                          movement=1, \n",
    "                          numbasis=numbasis, \n",
    "                          mode=\"ADI\")\n",
    "\n",
    "# Plot this reduced data cube. \n",
    "with fits.open(\"contrastcurves/FAKE_KLIP_ADI_A9K5S1M1-KLmodes-all.fits\") as hdulist:\n",
    "    adi_cube = hdulist[0].data\n",
    "    \n",
    "plt.figure()\n",
    "# plot the KL10 Cube (index of 2)\n",
    "plt.imshow(adi_cube[2], interpolation='nearest', cmap='inferno')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering Flux Values\n",
    "\n",
    "We can now visually inspect how well we were able to recover each injected planet, but if we want to quantify this algrorithm throughput, pyKLIP has a built in function \"retrieve_planet_flux\" so we can compare the retrieved flux to the input flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the centers of the output KLIP fits file\n",
    "with fits.open(\"contrastcurves/FAKE_KLIP_ADI_A9K5S1M1-KLmodes-all.fits\") as hdulist:\n",
    "    cube = hdulist[0].data[1]\n",
    "    cube_centers = [hdulist[0].header['PSFCENTX'], hdulist[0].header['PSFCENTY']]\n",
    "\n",
    "#Create and empty list to store retrieved flux values\n",
    "retrieved_fluxes = []\n",
    "\n",
    "#Retrieve planet fluxes\n",
    "for input_contrast, planet_sep in zip(input_contrasts, planet_seps):\n",
    "    \n",
    "    fake_planet_fluxes = []\n",
    "                                      \n",
    "    for pa in pas:\n",
    "        fake_flux = fakes.retrieve_planet_flux(frames = cube, \n",
    "                                            centers = cube_centers,\n",
    "                                            astr_hdrs = dataset.output_wcs[0], \n",
    "                                            sep = planet_sep,\n",
    "                                            pa = pa)\n",
    "        fake_planet_fluxes.append(fake_flux)\n",
    "\n",
    "    retrieved_fluxes.append(fake_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating throughput\n",
    "\n",
    "Now that we've run a full reduction on the data with injected planets, we can calculate the throughput to figure our how well we were able to recover the planet at different separations. \n",
    "\n",
    "Throughput can be calculated as follows: throughput = $\\frac{output\\ flux}{input\\ flux}$. We'll need to calculate the input flux first by multiplying our input contrasts by the peak star flux estimated from our previous Gaussian fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the input flux\n",
    "input_flux = [contrast*bestfit[0] for contrast in input_contrasts]\n",
    "\n",
    "#Put everything in table form (as a dataframe)\n",
    "throughput_table = pd.DataFrame(\n",
    "    {'retrieved_fluxes': retrieved_fluxes,\n",
    "     'input_flux': input_flux,\n",
    "     'separation': planet_seps\n",
    "     })\n",
    "\n",
    "#Calculate througput and put it in a column in the dataframe\n",
    "\n",
    "throughput_table[\"throughput\"] = throughput_table[\"retrieved_fluxes\"]/throughput_table[\"input_flux\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can visualize our throughput as a function of separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(throughput_table[\"separation\"], throughput_table[\"throughput\"])\n",
    "plt.xlabel(\"Separation (pixels)\")\n",
    "plt.ylabel(\"Throughput\")\n",
    "plt.title(\"Throughput as a Function of Separation from Star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving throughput\n",
    "\n",
    "From this plot, we can see that our throughput improves as a function of separation from the host star. Still, our plot is could benefit from a few more data points. If we could inject fake planets in every available space in our data, we'd get a much better sense of how throughput varies as a function of separation. However, this turns out to be quite tedious and messy. Instead, we'll inject only a few fake planets in an image, but do this for different separations in multiple images and record the throughput for each image. This will give us the same information in a much cleaner way.   \n",
    "\n",
    "To do this, we'll create a loop that injects 10 planets at a set list of separations, but changing the position angle each time. Every time it injects a new set of fake planets, it runs pyKLIP on the injected dataset, and then retrieves the fluxes of the fake planets from the KLIP-ed data to be output into a table.  \n",
    "Since we're using a loop to inject fake planets in new locations each time, we also need to regenerate a new dataset each time. Here we'll generate 10 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for dataset in range(10):\n",
    "    \n",
    "    #Import the dataset to be used\n",
    "    filtername = \"f300m\"\n",
    "\n",
    "    # read in roll 1\n",
    "    with fits.open(\"old_simulated_data/NIRCam_target_Roll1_{0}.fits\".format(filtername)) as hdulist:\n",
    "        roll1_cube = hdulist[0].data\n",
    "\n",
    "    # read in roll 2\n",
    "    with fits.open(\"old_simulated_data/NIRCam_target_Roll2_{0}.fits\".format(filtername)) as hdulist:\n",
    "        roll2_cube = hdulist[0].data  \n",
    "\n",
    "    # combine the two rows\n",
    "    full_seq = np.concatenate([roll1_cube, roll2_cube], axis=0)\n",
    "\n",
    "    # two rolls are offset 10 degrees\n",
    "    pas = np.append([0 for _ in range(roll1_cube.shape[0])], [10 for _ in range(roll2_cube.shape[0])])\n",
    "\n",
    "    # for each image, the (x,y) center where the star is is just the center of the image\n",
    "    centers = np.array([np.array(frame.shape)//2. for frame in full_seq])\n",
    "\n",
    "    # give it some names, just in case we want to refer to them\n",
    "    filenames = np.append([\"roll1_{0}\".format(i) for i in range(roll1_cube.shape[0])],\n",
    "                          [\"roll2_{0}\".format(i) for i in range(roll1_cube.shape[0])])\n",
    "\n",
    "    #Define dataset\n",
    "    dataset = Instrument.GenericData(full_seq, centers, IWA=4, parangs=pas, filenames=filenames)\n",
    "    dataset.flipx = False\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin the loop:\n",
    "\n",
    "1) Use our generated list of ten datasets  \n",
    "2) Specify input contrasts and planet separations  \n",
    "3) Specify starting position angle and amount by which to change position angle each loop\n",
    "4) Inject fake planets with  fakes.inject_planet  \n",
    "5) Run KLIP on fake injected dataset  \n",
    "6) Read in the KLIP-ed dataset  \n",
    "7) Retrieved fluxes of injected planets with fakes.retrieve_planet_flux  \n",
    "8) Append retrieved fluxes, planet separtions and contrasts to a list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_planets(input_contrasts, planet_seps, pas, pas_step_size):\n",
    "    \n",
    "    pas_all = [] \n",
    "    retrieved_fluxes_all = []\n",
    "    planet_seps_all = [] \n",
    "    input_contrasts_all = []\n",
    "    \n",
    "    #started changing pas\n",
    "    for dataset_num, dataset in enumerate(datasets):\n",
    "        \n",
    "        psf_stamp_input = np.array([psf_stamp for j in range(12)])\n",
    "        pas_array = [(x+pas_step_size*dataset_num*np.ones(12))-dataset.PAs for x in pas]\n",
    "        \n",
    "        start_over = False\n",
    "        for input_contrast, planet_sep, pa in zip(input_contrasts, planet_seps, pas):\n",
    "         \n",
    "            check_sep_x = planet_sep*np.cos((pa + 90)) \n",
    "            check_sep_y = planet_sep*np.sin((pa + 90))\n",
    "            \n",
    "            dist_p1 = np.sqrt((check_sep_x - planet1_peak_x)**2 + (check_sep_y - planet1_peak_y)**2)\n",
    "            dist_p2 = np.sqrt((check_sep_x - planet2_peak_x)**2 + (check_sep_y - planet2_peak_y)**2)\n",
    "            \n",
    "            if dist_p1 > 12 and dist_p2 > 12:\n",
    "                planet_fluxes = psf_stamp_input*input_contrast\n",
    "\n",
    "\n",
    "                fakes.inject_planet(frames = dataset.input, \n",
    "                                    centers=dataset.centers, \n",
    "                                    inputflux=planet_fluxes, \n",
    "                                    astr_hdrs=dataset.wcs, \n",
    "                                    radius=planet_sep,\n",
    "                                    pa = pa)\n",
    "            else:\n",
    "                start_over = True\n",
    "                \n",
    "        if start_over:\n",
    "            continue\n",
    "            \n",
    "\n",
    "\n",
    "        #Set output directory\n",
    "        outputdir = 'contrastcurves'\n",
    "        fileprefix = 'FAKE_KLIP_ADI_A9K5S4M1' + str(dataset_num)\n",
    "        numbasis = [1,5,10,20,50]\n",
    "\n",
    "\n",
    "        #Run KLIP on dataset with injected fakes\n",
    "        parallelized.klip_dataset(dataset, \n",
    "                                  outputdir=outputdir, \n",
    "                                  fileprefix=fileprefix, \n",
    "                                  algo = 'klip', \n",
    "                                  annuli=1, \n",
    "                                  subsections=1, \n",
    "                                  movement=1, \n",
    "                                  numbasis=numbasis, \n",
    "                                  mode=\"ADI\")\n",
    "\n",
    "\n",
    "        # replace os.path.join(foldername,filename)\n",
    "        klipdataset = \"contrastcurves/\"+ fileprefix + \"-KLmodes-all.fits\"\n",
    "        with fits.open(klipdataset) as hdulist:\n",
    "            outputfile = hdulist[0].data\n",
    "            outputfile_centers = [hdulist[0].header['PSFCENTX'], hdulist[0].header['PSFCENTY']]\n",
    "\n",
    "        outputfile_frame = outputfile[2]\n",
    "\n",
    "        thetas_retrieve = [x+thetas_step_size*dataset_num for x in thetas]\n",
    "        retrieved_planet_fluxes = []\n",
    "\n",
    "\n",
    "        #retrieving planet flux\n",
    "        for input_contrast, planet_sep, pa in zip(input_contrasts, planet_seps, pas):\n",
    "\n",
    "            fake_flux = fakes.retrieve_planet_flux(frames = outputfile_frame, \n",
    "                                                    centers=outputfile_centers,\n",
    "                                                    astr_hdrs=dataset.output_wcs[0], \n",
    "                                                    sep=planet_sep,\n",
    "                                                    pa = pa,\n",
    "                                                    searchrad = 7)\n",
    "\n",
    "            retrieved_planet_fluxes.append(fake_flux)\n",
    "            \n",
    "        \n",
    "        retrieved_fluxes_all.append(retrieved_planet_fluxes)\n",
    "        pas_all.append(pas)\n",
    "        planet_seps_all.append(planet_seps)\n",
    "        input_contrasts_all.append[input_contrasts]\n",
    "        \n",
    "        \n",
    "    return pas_all, retrieved_fluxes_all, planet_seps_all, input_contrasts_all\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas, retrieved_fluxes, planet_seps, input_contrasts = test_multiple_planets(input_contrasts = [3e-3, 2e-3, 1e-3, 3e-3],\n",
    "          planet_seps = [10,12, 15,20],\n",
    "          pas = [0, 60, 210, 270], \n",
    "          pas_step_size = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate throughput\n",
    "\n",
    "We can first create a table using the lists of retrieved planets fluxes, their separations and input fluxes. Then, we'll add the column \"throughput\" which will hold the throughput calculations for each value in the table. The throughput calculation is: $\\frac{Retrieved\\ flux}{Input\\ flux}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "#Loop through each list to create a table of all variables\n",
    "for flux, sep, input_contrast, pa in zip(retrieved_fluxes_all, planet_seps_all, input_contrasts_all, pas_all):\n",
    "    input_flux = np.array(input_contrast)*bestfit[0]\n",
    "    t = Table([flux,sep, input_flux, pas], names = ('flux', 'separation', 'input_flux', 'thetas'))\n",
    "    \n",
    "    tables.append(t)\n",
    "flux_sep = vstack([x for x in tables])\n",
    "#Calculate throughput and add it to list \n",
    "flux_sep['throughput'] = flux_sep['flux']/flux_sep['input_flux']\n",
    "\n",
    "#We can also calculate the median througput per separation\n",
    "\n",
    "#Group by separation\n",
    "flux_by_sep = flux_sep.group_by('separation')\n",
    "\n",
    "#Calculate the median value for each separation group\n",
    "med_flux_by_sep = flux_by_sep.groups.aggregate(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.scatter(flux_sep[\"separation\"], flux_sep[\"throughput\"], color = '#BC96E6', label = \"Calculated Throughputs\")\n",
    "plt.plot(med_flux_by_sep[\"separation\"], med_flux_by_sep[\"throughput\"], color = 'red', label = \"Median Throughput\")\n",
    "plt.ylabel(\"Throughput\")\n",
    "plt.xlabel(\"Planet Separation\")\n",
    "plt.title(\"Algorithm Throughput\")\n",
    "plt.legend(frameon = False)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.savefig(\"throughput_med.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
