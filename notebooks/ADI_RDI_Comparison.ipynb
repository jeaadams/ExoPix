{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import pyklip.klip\n",
    "import pyklip.instruments.Instrument as Instrument\n",
    "import pyklip.parallelized as parallelized\n",
    "import pyklip.rdi as rdi\n",
    "import pyklip.fakes as fakes\n",
    "import glob\n",
    "from astropy.table import Table\n",
    "from astropy.table import join\n",
    "from astropy.table import vstack\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's specifiy the important variables first. Change this as needed.\n",
    "mode = 'RDI' \n",
    "datadir = 'old_simulated_data'\n",
    "filtername = \"f300m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(datadir, filtername,  num_datasets=1, mode = 'ADI'):\n",
    "    \"\"\"\n",
    "    Generates multiple generic datasets based on the two JWST roll angles 0° and 10°\n",
    "    Args:\n",
    "        datadir (str): The directory the data is contained in\n",
    "        filtername (str): The name of the filter you'd like to use\n",
    "        num_datasets(int): Number of datasets to be generated. Default is 1.\n",
    "        data_type (str): The type of data reduction you'd like to generate data for (adi or rdi). adi is default\n",
    "    Returns:\n",
    "        list: List of generated datasets\n",
    "        list: Library of \n",
    "    \"\"\"\n",
    "    if mode not in ('ADI','RDI'):\n",
    "        raise ValueError(f\"Uknown data type {mode}\")\n",
    "    \n",
    "    # Use this function if mode is adi\n",
    "    def _process_adi(num_datasets):\n",
    "        datasets = []\n",
    "        psflibs = []\n",
    "        for dataset in range(num_datasets):\n",
    "            # Read in roll 1\n",
    "            with fits.open(f\"{datadir}/NIRCam_target_Roll1_{filtername}.fits\") as hdulist:\n",
    "                roll1_cube = hdulist[0].data\n",
    "            # Read in roll 2\n",
    "            with fits.open(f\"{datadir}/NIRCam_target_Roll2_{filtername}.fits\") as hdulist:\n",
    "                roll2_cube = hdulist[0].data\n",
    "            # Combine the two rows\n",
    "            full_seq = np.concatenate([roll1_cube, roll2_cube], axis=0)\n",
    "            # Two rolls are offset 10 degrees\n",
    "            pas = np.append([0 for _ in range(roll1_cube.shape[0])], [10 for _ in range(roll2_cube.shape[0])])\n",
    "            # For each image, the (x,y) center where the star is is just the center of the image\n",
    "            centers = np.array([np.array(frame.shape) // 2.0 for frame in full_seq])\n",
    "            # Give it some names, just in case we want to refer to them\n",
    "            filenames = np.append([\"roll1_{0}\".format(i) for i in range(roll1_cube.shape[0])],[\"roll2_{0}\".format(i) for i in range(roll1_cube.shape[0])])\n",
    "            # Define dataset\n",
    "            dataset = Instrument.GenericData(full_seq, centers, IWA=4, parangs=pas, filenames=filenames)\n",
    "            dataset.flipx = False\n",
    "            psflib = None\n",
    "            if num_datasets > 1:\n",
    "                datasets.append(dataset)\n",
    "                psflibs.append(psflib)\n",
    "            else:\n",
    "                datasets = dataset\n",
    "                psflibs = psflib\n",
    "        return datasets, psflibs\n",
    "    \n",
    "    # Use this function if mode is rdi\n",
    "    def _process_rdi(num_datasets):\n",
    "        datasets = []\n",
    "        psflibs = []\n",
    "        for dataset in range(num_datasets):\n",
    "            # read in ref star\n",
    "            with fits.open(f\"{datadir}/NIRCam_refs_SGD_{filtername}.fits\") as hdulist:\n",
    "                ref_cube = hdulist[0].data\n",
    "            # Read in roll 1\n",
    "            with fits.open(f\"{datadir}/NIRCam_target_Roll1_{filtername}.fits\") as hdulist:\n",
    "                roll1_cube = hdulist[0].data\n",
    "            # Read in roll 2\n",
    "            with fits.open(f\"{datadir}/NIRCam_target_Roll2_{filtername}.fits\") as hdulist:\n",
    "                roll2_cube = hdulist[0].data\n",
    "                \n",
    "            # Combine the two rows\n",
    "            full_seq = np.concatenate([roll1_cube, roll2_cube], axis=0)\n",
    "\n",
    "            # Two rolls are offset 10 degrees\n",
    "            pas = np.append([0 for _ in range(roll1_cube.shape[0])], [10 for _ in range(roll2_cube.shape[0])])\n",
    "\n",
    "            # For each image, the (x,y) center where the star is is just the center of the image\n",
    "            centers = np.array([np.array(frame.shape) // 2.0 for frame in full_seq])\n",
    "\n",
    "            # Give it some names, just in case we want to refer to them\n",
    "            filenames = np.append([\"roll1_{0}\".format(i) for i in range(roll1_cube.shape[0])],[\"roll2_{0}\".format(i) for i in range(roll1_cube.shape[0])])\n",
    "\n",
    "            # create the GenericData object. This will standardize the data for pyKLIP\n",
    "            dataset = Instrument.GenericData(full_seq, centers, IWA=4, parangs=pas, filenames=filenames)\n",
    "            dataset.flipx = False # get the right handedness of the data\n",
    "\n",
    "            # combine both science target and reference target images into a psf library array\n",
    "            psflib_imgs = np.append(ref_cube, full_seq, axis=0)\n",
    "\n",
    "            ref_filenames = [\"ref_{0}\".format(i) for i in range(ref_cube.shape[0])]\n",
    "            psflib_filenames = np.append(ref_filenames, filenames, axis=0)\n",
    "            # all frames aligned to image center (Which are the same size)\n",
    "            ref_center = np.array(ref_cube[0].shape)/2\n",
    "\n",
    "            # make the PSF library\n",
    "            # we need to compute the correlation matrix of all images vs each other since we haven't computed it before\n",
    "            psflib = rdi.PSFLibrary(psflib_imgs, ref_center, psflib_filenames, compute_correlation=True)\n",
    "\n",
    "            if num_datasets > 1:\n",
    "                datasets.append(dataset)\n",
    "                psflibs.append(psflib)\n",
    "            else:\n",
    "                datasets = dataset\n",
    "                psflibs = psflib\n",
    "                \n",
    "        return datasets, psflibs\n",
    "    \n",
    "    return _process_adi(num_datasets) if mode == 'ADI' else _process_rdi(num_datasets) if mode == 'RDI' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RAW contrast w/ RDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Specifying KLIP params. Change as desired\n",
    "outputdir = \"./\"\n",
    "fileprefix = f\"pyklip-f300m-{mode}-k50a9s4\"\n",
    "annuli = 9\n",
    "subsections = 4\n",
    "movement = 1\n",
    "\n",
    "# Generate dataset for use\n",
    "\n",
    "dataset, psflib = generate_datasets(datadir, filtername, num_datasets=1, mode = mode)\n",
    "\n",
    "if mode == 'RDI':\n",
    "    psflib.prepare_library(dataset)\n",
    "\n",
    "# Run pyKLIP RDI\n",
    "parallelized.klip_dataset(dataset, outputdir=outputdir, fileprefix=fileprefix, annuli=annuli, \n",
    "                      subsections=subsections, numbasis=[1,5,10,20,50], movement = movement, mode=mode, psf_library=psflib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask real planets in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pyKLIP RDI\n",
    "parallelized.klip_dataset(dataset, outputdir=outputdir, fileprefix=fileprefix, annuli=annuli, \n",
    "                      subsections=subsections, numbasis=[1,5,10,20,50], movement = movement, mode=mode, psf_library=psflib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the KLIP-ed dataset\n",
    "filesuffix = \"-KLmodes-all.fits\"\n",
    "\n",
    "with fits.open(f\"{fileprefix}{filesuffix}\") as hdulist:\n",
    "    reduced_cube = hdulist[0].data\n",
    "    reduced_centers = [hdulist[0].header[\"PSFCENTX\"], hdulist[0].header[\"PSFCENTY\"]]\n",
    "\n",
    "\n",
    "# Plot the KL10 Cube (index of 2)\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.imshow(reduced_cube[2], interpolation=\"nearest\", cmap=\"inferno\", vmin=0, vmax=5)\n",
    "\n",
    "# Find the positions of the 'real' planets\n",
    "real_x = [41, 43]\n",
    "real_y = [54, 70]\n",
    "\n",
    "# Place green circles around the real planets\n",
    "for j in range(len(real_x)):\n",
    "    circle2 = plt.Circle((real_x[j], real_y[j]), 4, fill=False, edgecolor=\"green\", ls=\"-\", linewidth=3)\n",
    "    ax1.add_artist(circle2)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "ax1.set_xlabel(\"pixels\")\n",
    "ax1.set_ylabel(\"pixels\")\n",
    "ax1.set_title(\"PSF Subtracted Image\")\n",
    "\n",
    "# Mask the 1st planet\n",
    "planet1_peak_x = 41\n",
    "planet1_peak_y = 54\n",
    "\n",
    "# Create an array with the indices are that of KL mode frame with index 2\n",
    "ydat, xdat = np.indices(reduced_cube[2].shape)\n",
    "\n",
    "# Set the FWHM of the PSF\n",
    "psf_fwhm = 6\n",
    "\n",
    "# Calculate the distance around the planet to be masked\n",
    "distance_from_planet1 = np.sqrt((xdat - planet1_peak_x) ** 2 + (ydat - planet1_peak_y) ** 2)\n",
    "\n",
    "# Mask\n",
    "reduced_cube[2][np.where(distance_from_planet1 <= 2 * psf_fwhm)] = np.nan\n",
    "\n",
    "# Mask the second planet\n",
    "planet2_peak_x = 43\n",
    "planet2_peak_y = 70\n",
    "distance_from_planet2 = np.sqrt((xdat - planet2_peak_x) ** 2 + (ydat - planet2_peak_y) ** 2)\n",
    "reduced_cube[2][np.where(distance_from_planet2 <= 2 * psf_fwhm)] = np.nan\n",
    "\n",
    "# Plot the new masked data\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.imshow(reduced_cube[2], interpolation=\"nearest\", cmap=\"inferno\", vmin = 0, vmax = 10)\n",
    "plt.gca().invert_yaxis()\n",
    "ax2.set_xlabel(\"pixels\")\n",
    "ax2.set_ylabel(\"pixels\")\n",
    "ax2.set_title(\"Real Planets Masked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWA = 65  # Setting this to be distance between star and outer edge of image\n",
    "\n",
    "# Measuring the contrast in the image\n",
    "contrast_seps, contrast = pyklip.klip.meas_contrast(dat=reduced_cube[2], iwa=dataset.IWA, owa=OWA, resolution=(psf_fwhm), center=reduced_centers, low_pass_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize contrast measurements with unocculted psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in unocculted PSF\n",
    "with fits.open(f\"{datadir}/NIRCam_unocculted_{filtername}.fits\") as hdulist:\n",
    "    psf_cube = hdulist[0].data\n",
    "    psf_head = hdulist[0].header\n",
    "\n",
    "# Collapse reference psf in time\n",
    "psf_frame = np.nanmean(psf_cube, axis=0)\n",
    "\n",
    "# Find the centroid\n",
    "bestfit = fakes.gaussfit2d(psf_frame, 71, 30, searchrad=3, guessfwhm=2, guesspeak=1, refinefit=True)\n",
    "\n",
    "psf_xcen, psf_ycen = bestfit[2:4]\n",
    "peak_flux = bestfit[0]\n",
    "\n",
    "# Recenter PSF to that location\n",
    "x, y = np.meshgrid(np.arange(-20, 20.1, 1), np.arange(-20, 20.1, 1))\n",
    "x += psf_xcen\n",
    "y += psf_ycen\n",
    "\n",
    "psf_stamp = scipy.ndimage.map_coordinates(psf_frame, [y, x])\n",
    "\n",
    "\n",
    "norm_contrast = contrast / peak_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that does the planet injection and retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the transmission profile csv\n",
    "mask210 = pd.read_csv(\"MASK210R.csv\")\n",
    "\n",
    "# Create the throughput correction function\n",
    "def transmission_corrected(input_stamp, input_dx, input_dy):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_stamp (array): 2D array of the region surrounding the fake planet injection site\n",
    "        input_dx (array): 2D array specifying the x distance of each stamp pixel from the center\n",
    "        input_dy (array): 2D array specifying the y distance of each stamp pixel from the center\n",
    "        \n",
    "    Returns:\n",
    "        output_stamp (array): 2D array of the throughput corrected planet injection site.\n",
    "        \"\"\"\n",
    "\n",
    "    # Calculate the distance of each pixel in the input stamp from the center\n",
    "    distance_from_center = np.sqrt((input_dx) ** 2 + (input_dy) ** 2)\n",
    "\n",
    "    # Interpolate to find the transmission value for each pixel in the input stamp (we need to turn the columns into arrays so np.interp can accept them)\n",
    "    distance = np.array(mask210[\"rad_dist\"])\n",
    "    transmission = np.array(mask210[\"trans\"])\n",
    "    trans_at_dist = np.interp(distance_from_center, distance, transmission)\n",
    "\n",
    "    # Reshape the interpolated array to have the same dimensions as the input stamp\n",
    "    transmission_stamp = trans_at_dist.reshape(input_stamp.shape)\n",
    "\n",
    "    # Make the throughput correction\n",
    "    output_stamp = transmission_stamp * input_stamp\n",
    "\n",
    "    return output_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_planet_injection(datadir, filtername, seps, input_pas, num_datasets, input_contrasts, mode):\n",
    "    \n",
    "    \"\"\"\n",
    "    Injects multiple fake planets across multiple datasets.\n",
    "\n",
    "    Args:\n",
    "        datadir (str): The name of the directory that the data is contained in\n",
    "        filtername (str) The name of the filter to be used\n",
    "        seps (list: int): List of separations each planet should be injected at\n",
    "        input_pas (list: int): List of position angles to inject fake planets at \n",
    "        num_datastes(int): The number of datasets to be generated. This is equal to the number of interations of planet injection/number of position angle changes\n",
    "        input_contrasts(list: float): List of contrasts planets should be injected at\n",
    "    Returns:\n",
    "        retrieved_fluxes_all (list): All retrieved planet fluxes\n",
    "        pas_all (list): All position angles used for injection\n",
    "        planet_seps_all (list): All planet separations used for injection\n",
    "        input_contrasts_all (list): All planet contrasts used for injection\n",
    "    \"\"\"\n",
    "    \n",
    "    pas_all = []\n",
    "    retrieved_fluxes_all = []\n",
    "    planet_seps_all = []\n",
    "    input_contrasts_all = []\n",
    "    \n",
    "    # Generate desired number of datasets: number of loops at each separation\n",
    "    datasets, psflibs = generate_datasets(datadir, filtername, num_datasets=num_datasets, mode = mode)\n",
    "\n",
    "    # Begin fake planet injection and retrieval, changing position angle each time\n",
    "    for dataset_num, dataset, psflib in zip(range(len(datasets)), datasets, psflibs):\n",
    "        if mode == 'RDI':\n",
    "            psflib.prepare_library(dataset)\n",
    "\n",
    "        # Create stamps of the point spread function to be injected as a fake planet\n",
    "        psf_stamp_input = np.array([psf_stamp for j in range(12)])\n",
    "        \n",
    "        # Clock the position angles of the injected planets by 40 each time\n",
    "        input_pas = [x+40*dataset_num for x in input_pas]\n",
    "\n",
    "        start_over = False\n",
    "\n",
    "        # Inject fake planets\n",
    "        for input_contrast, sep, pa in zip(input_contrasts, seps, input_pas):\n",
    "\n",
    "            # Check the distance between the planet to be injected and the real planets. We don't want to inject fake planets too close to the two planets already in the data.\n",
    "            check_sep_x = sep * np.cos((pa + 90))\n",
    "            check_sep_y = sep * np.sin((pa + 90))\n",
    "            dist_p1 = np.sqrt((check_sep_x - planet1_peak_x)**2 + (check_sep_y - planet1_peak_y)**2)\n",
    "            dist_p2 = np.sqrt((check_sep_x - planet2_peak_x)**2 + (check_sep_y - planet2_peak_y)**2)\n",
    "\n",
    "            # Make sure fake planets won't be injected within a 12 pixel radius of the real planets\n",
    "            if dist_p1 > 12 and dist_p2 > 12:\n",
    "\n",
    "                planet_fluxes = psf_stamp_input * input_contrast\n",
    "                fakes.inject_planet(frames=dataset.input, centers=dataset.centers, inputflux=planet_fluxes, astr_hdrs=dataset.wcs, radius=sep, pa=pa, field_dependent_correction=transmission_corrected)\n",
    "\n",
    "            # If the fake planet to be injected is within a 12 pixel radius of the real planets, start the loop over\n",
    "            else:\n",
    "                start_over = True\n",
    "\n",
    "        if start_over:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "\n",
    "        # Run KLIP on datasets with injected planets: Set output directory\n",
    "        outputdir = \"contrastcurves\"\n",
    "        fileprefix = f\"FAKE_KLIP_{mode}_A9K5S4M1_{str(dataset_num)}{str(n_sep_loops)}\"\n",
    "        filename =  f\"FAKE_KLIP_{mode}_A9K5S4M1_{str(dataset_num)}{str(n_sep_loops)}-KLmodes-all.fits\"\n",
    "        numbasis = [1, 5, 10, 20, 50]\n",
    "\n",
    "        # Run KLIP \n",
    "        parallelized.klip_dataset(dataset, outputdir=outputdir, fileprefix=fileprefix, algo=\"klip\", annuli=9, subsections=4, movement=1, numbasis=numbasis, mode=mode, verbose=False, psf_library=psflib)\n",
    "\n",
    "        # Open one frame of the KLIP-ed dataset\n",
    "        klipdataset = os.path.join(outputdir, filename)\n",
    "        with fits.open(klipdataset) as hdulist:\n",
    "            outputfile = hdulist[0].data\n",
    "            outputfile_centers = [hdulist[0].header[\"PSFCENTX\"], hdulist[0].header[\"PSFCENTY\"]]\n",
    "        outputfile_frame = outputfile[2]\n",
    "\n",
    "        # Retrieve planet fluxes\n",
    "        retrieved_planet_fluxes = []\n",
    "        for input_contrast, sep, pa in zip(input_contrasts, seps, input_pas):\n",
    "\n",
    "            fake_flux = fakes.retrieve_planet_flux(frames=outputfile_frame, centers=outputfile_centers, astr_hdrs=dataset.output_wcs[0], sep=sep, pa=pa, searchrad=7)\n",
    "            retrieved_planet_fluxes.append(fake_flux)\n",
    "        retrieved_fluxes_all.extend(retrieved_planet_fluxes)\n",
    "        pas_all.extend(input_pas)\n",
    "        planet_seps_all.extend(seps)\n",
    "        input_contrasts_all.extend(input_contrasts)\n",
    "        \n",
    "    return retrieved_fluxes_all, pas_all, planet_seps_all, input_contrasts_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use a loop to make numerous measurements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separation variables \n",
    "min_sep = 12\n",
    "max_sep = 40\n",
    "nplanets = 4\n",
    "dist_bt_planets = 3\n",
    "num_datasets = 3\n",
    "input_pas = [0, 30, 60, 120]\n",
    "\n",
    "# Maximum separation of first iteration\n",
    "max_sep_1 = min_sep + dist_bt_planets * nplanets\n",
    "\n",
    "# Number of times to iterate to get to max desired separation (max desired sep - max sep in first iteration)\n",
    "n_sep_loops = max_sep - max_sep_1\n",
    "\n",
    "retrieved_fluxes_all_rdi = []\n",
    "output_pas_all_rdi = []\n",
    "planet_seps_all_rdi = []\n",
    "output_contrasts_all_rdi = []\n",
    "\n",
    "for n in tqdm(range(n_sep_loops)):\n",
    "    # Create array of separations and contrasts to be injected at, spaced by desired distance b/t planets\n",
    "    seps = np.arange(min_sep + n, max_sep_1 + n, dist_bt_planets)\n",
    "    input_contrasts = (np.interp(seps, contrast_seps, norm_contrast))*5\n",
    "    \n",
    "    retrieved_fluxes, output_pas, output_planet_seps, output_contrasts = multiple_planet_injection(datadir, filtername, seps, input_pas, num_datasets, input_contrasts, mode)\n",
    "    \n",
    "    retrieved_fluxes_all_rdi.extend(retrieved_fluxes)\n",
    "    output_pas_all_rdi.extend(output_pas)\n",
    "    planet_seps_all_rdi.extend(output_planet_seps)\n",
    "    output_contrasts_all_rdi.extend(output_contrasts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of all variables\n",
    "flux_sep_rdi = Table([retrieved_fluxes_all_rdi, planet_seps_all_rdi, output_contrasts_all_rdi, output_pas_all_rdi], names=(\"flux\", \"separation\", \"input_contrast\", \"pas\"))\n",
    "flux_sep_rdi[\"input_flux\"] = flux_sep_rdi[\"input_contrast\"] * bestfit[0]\n",
    "\n",
    "# Calculate throughput and add it to the table\n",
    "flux_sep_rdi[\"throughput\"] = flux_sep_rdi[\"flux\"] / flux_sep_rdi[\"input_flux\"]\n",
    "\n",
    "# Group by separation\n",
    "med_flux_sep_rdi = flux_sep_rdi.group_by(\"separation\")\n",
    "\n",
    "# Calculate the median value for each separation group\n",
    "med_flux_sep_rdi = med_flux_sep_rdi.groups.aggregate(np.median)\n",
    "\n",
    "# Find the 5 sigma contrast for each separation used in calculation\n",
    "med_flux_sep_rdi['5sig_contrast']=np.interp(med_flux_sep_rdi['separation'],contrast_seps, norm_contrast)\n",
    "\n",
    "# Normalize the noise contrast by the measured throughput level at that separation\n",
    "med_flux_sep_rdi[\"corrected_contrast\"] = (med_flux_sep_rdi[\"5sig_contrast\"] / med_flux_sep_rdi[\"throughput\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the same thing for adi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ADI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute contrast measurement again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying KLIP params. Change as desired\n",
    "outputdir = \"./\"\n",
    "fileprefix = f\"pyklip-f300m-{mode}-k50a9s4\"\n",
    "annuli = 9\n",
    "subsections = 4\n",
    "movement = 1\n",
    "\n",
    "# Generate dataset for use\n",
    "dataset, psflib = generate_datasets(datadir, filtername, num_datasets=1, mode = mode)\n",
    "\n",
    "if mode == 'RDI':\n",
    "    psflib.prepare_library(dataset)\n",
    "    \n",
    "# Run pyKLIP RDI\n",
    "parallelized.klip_dataset(dataset, outputdir=outputdir, fileprefix=fileprefix, annuli=annuli, \n",
    "                      subsections=subsections, numbasis=[1,5,10,20,50], movement = movement, mode=mode, psf_library=psflib)\n",
    "\n",
    "\n",
    "# Read in the KLIP-ed dataset\n",
    "filesuffix = \"-KLmodes-all.fits\"\n",
    "\n",
    "with fits.open(f\"{fileprefix}{filesuffix}\") as hdulist:\n",
    "    reduced_cube = hdulist[0].data\n",
    "    reduced_centers = [hdulist[0].header[\"PSFCENTX\"], hdulist[0].header[\"PSFCENTY\"]]\n",
    "\n",
    "\n",
    "# Find the positions of the 'real' planets\n",
    "real_x = [41, 43]\n",
    "real_y = [54, 70]\n",
    "\n",
    "# Mask the 1st planet\n",
    "planet1_peak_x = 41\n",
    "planet1_peak_y = 54\n",
    "\n",
    "# Create an array with the indices are that of KL mode frame with index 2\n",
    "ydat, xdat = np.indices(reduced_cube[2].shape)\n",
    "\n",
    "# Set the FWHM of the PSF\n",
    "psf_fwhm = 6\n",
    "\n",
    "# Calculate the distance around the planet to be masked\n",
    "distance_from_planet1 = np.sqrt((xdat - planet1_peak_x) ** 2 + (ydat - planet1_peak_y) ** 2)\n",
    "\n",
    "# Mask\n",
    "reduced_cube[2][np.where(distance_from_planet1 <= 2 * psf_fwhm)] = np.nan\n",
    "\n",
    "# Mask the second planet\n",
    "planet2_peak_x = 43\n",
    "planet2_peak_y = 70\n",
    "distance_from_planet2 = np.sqrt((xdat - planet2_peak_x) ** 2 + (ydat - planet2_peak_y) ** 2)\n",
    "reduced_cube[2][np.where(distance_from_planet2 <= 2 * psf_fwhm)] = np.nan\n",
    "\n",
    "OWA = 65  # Setting this to be distance between star and outer edge of image\n",
    "\n",
    "# Measuring the contrast in the image\n",
    "contrast_seps_adi, contrast_adi = pyklip.klip.meas_contrast(dat=reduced_cube[2], iwa=dataset.IWA, owa=OWA, resolution=(psf_fwhm), center=reduced_centers, low_pass_filter=False)\n",
    "\n",
    "norm_contrast_adi = contrast_adi / peak_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define separation variables \n",
    "min_sep = 12\n",
    "max_sep = 40\n",
    "nplanets = 4\n",
    "dist_bt_planets = 3\n",
    "num_datasets = 3\n",
    "input_pas = [0, 30, 60, 120]\n",
    "\n",
    "# Maximum separation of first iteration\n",
    "max_sep_1 = min_sep + dist_bt_planets * nplanets\n",
    "\n",
    "# Number of times to iterate to get to max desired separation (max desired sep - max sep in first iteration)\n",
    "n_sep_loops = max_sep - max_sep_1\n",
    "\n",
    "retrieved_fluxes_all_adi = []\n",
    "output_pas_all_adi = []\n",
    "planet_seps_all_adi = []\n",
    "output_contrasts_all_adi = []\n",
    "\n",
    "for n in tqdm(range(n_sep_loops)):\n",
    "    # Create array of separations and contrasts to be injected at, spaced by desired distance b/t planets\n",
    "    seps = np.arange(min_sep + n, max_sep_1 + n, dist_bt_planets)\n",
    "    input_contrasts = (np.interp(seps, contrast_seps, norm_contrast_adi))*5\n",
    "    \n",
    "    retrieved_fluxes, output_pas, output_planet_seps, output_contrasts = multiple_planet_injection(datadir, filtername, seps, input_pas, num_datasets, input_contrasts, mode)\n",
    "    \n",
    "    retrieved_fluxes_all_adi.extend(retrieved_fluxes)\n",
    "    output_pas_all_adi.extend(output_pas)\n",
    "    planet_seps_all_adi.extend(output_planet_seps)\n",
    "    output_contrasts_all_adi.extend(output_contrasts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of all variables\n",
    "flux_sep_adi = Table([retrieved_fluxes_all_adi, planet_seps_all_adi, output_contrasts_all_adi, output_pas_all_adi], names=(\"flux\", \"separation\", \"input_contrast\", \"pas\"))\n",
    "flux_sep_adi[\"input_flux\"] = flux_sep_adi[\"input_contrast\"] * bestfit[0]\n",
    "\n",
    "# Calculate throughput and add it to the table\n",
    "flux_sep_adi[\"throughput\"] = flux_sep_adi[\"flux\"] / flux_sep_adi[\"input_flux\"]\n",
    "\n",
    "# Group by separation\n",
    "med_flux_sep_adi = flux_sep_adi.group_by(\"separation\")\n",
    "\n",
    "# Calculate the median value for each separation group\n",
    "med_flux_sep_adi = med_flux_sep_adi.groups.aggregate(np.median)\n",
    "\n",
    "# Find the 5 sigma contrast for each separation used in calculation\n",
    "med_flux_sep_adi['5sig_contrast']=np.interp(med_flux_sep_adi['separation'],contrast_seps_adi, norm_contrast_adi)\n",
    "\n",
    "# Normalize the noise contrast by the measured throughput level at that separation\n",
    "med_flux_sep_adi[\"corrected_contrast\"] = (med_flux_sep_adi[\"5sig_contrast\"] / med_flux_sep_adi[\"throughput\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(med_flux_sep[\"separation\"], med_flux_sep[\"corrected_contrast\"], color=\"purple\", linewidth = 3, label = 'RDI')\n",
    "plt.plot(med_flux_sep_adi[\"separation\"], med_flux_sep_adi[\"corrected_contrast\"], color=\"purple\", linewidth = 3, label = 'ADI')\n",
    "plt.plot(med_flux_sep_rdi[\"separation\"], med_flux_sep_rdi[\"corrected_contrast\"], color=\"pink\", linewidth = 3, label = 'RDI')\n",
    "plt.legend(frameon = False)\n",
    "plt.xlim(5,40)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Contrast\")\n",
    "plt.xlabel(\"Separation (pixels)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
